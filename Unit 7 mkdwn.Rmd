---
title: "Unit 7 FLS"
author: "Miguel Bonilla"
date: "2/12/2022"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{r}
library(plyr)
library(tidyverse)
library(caret)
library(e1071)
library(ggthemes)
library(tm)
library(jsonlite)

```


```{r}
#load the titanic file first
titan <- read.csv("titanic_train.csv", colClasses = c("Sex" = "factor","Survived"="factor"))
titan$Survived <- recode_factor(titan$Survived, "0"="Perished", "1"="Survived")

```

```{r}
#use all observations on original table and train a NB model to predict
Titanicall <- titan %>% select(Age, Pclass, Survived)
#Titanicall$Survived[Titanicall$Survived == "0"] <- "Perished"
#Titanicall$Survived[Titanicall$Survived == "1"] <- "Survived"
model <- naiveBayes(Survived~.,Titanicall, laplace = 3)
df <- data.frame(predict(model,Titanicall, type="raw"))
print(df,n=30)

```


```{r}
#split the observations into a training and test set 70-30
titanicclean <- titan %>% filter(!is.na(Age)& !is.na(Pclass))
set.seed(4) #assigned
trainIndices <- sample(seq(1:length(titanicclean$Age)), round(.7*length(titanicclean$Age)))
trainTitanic <- titanicclean[trainIndices,]
testTitanic <- titanicclean[-trainIndices,]

head(trainTitanic)
head(testTitanic)

```


```{r}
#train model using train set

model <- naiveBayes(trainTitanic[,c(6,3)],trainTitanic$Survived)
df <- data.frame(classification=predict(model,testTitanic))
cm <- confusionMatrix(df$classification,testTitanic$Survived)
cm

```


```{r}
set.seed(4)#return to seed 4
#set seed 6
titanicclean <- titan %>% filter(!is.na(Age)& !is.na(Pclass))
set.seed(6) #6
trainIndices <- sample(seq(1:length(titanicclean$Age)), round(.7*length(titanicclean$Age)))
trainTitanic <- titanicclean[trainIndices,]
testTitanic <- titanicclean[-trainIndices,]

model <- naiveBayes(trainTitanic[,c(6,3)],trainTitanic$Survived)
df <- data.frame(classification=predict(model,testTitanic))
cm <- confusionMatrix(df$classification,testTitanic$Survived)
cm

#set seed 20
titanicclean <- titan %>% filter(!is.na(Age)& !is.na(Pclass))
set.seed(20) #20
trainIndices <- sample(seq(1:length(titanicclean$Age)), round(.7*length(titanicclean$Age)))
trainTitanic <- titanicclean[trainIndices,]
testTitanic <- titanicclean[-trainIndices,]

model <- naiveBayes(trainTitanic[,c(6,3)],trainTitanic$Survived)
df <- data.frame(classification=predict(model,testTitanic))
cm <- confusionMatrix(df$classification,testTitanic$Survived)
cm

#set seed 60
titanicclean <- titan %>% filter(!is.na(Age)& !is.na(Pclass))
set.seed(60) #60
trainIndices <- sample(seq(1:length(titanicclean$Age)), round(.7*length(titanicclean$Age)))
trainTitanic <- titanicclean[trainIndices,]
testTitanic <- titanicclean[-trainIndices,]

model <- naiveBayes(trainTitanic[,c(6,3)],trainTitanic$Survived)
df <- data.frame(classification=predict(model,testTitanic))
cm <- confusionMatrix(df$classification,testTitanic$Survived)
cm

#set seed 85
titanicclean <- titan %>% filter(!is.na(Age)& !is.na(Pclass))
set.seed(85) #85
trainIndices <- sample(seq(1:length(titanicclean$Age)), round(.7*length(titanicclean$Age)))
trainTitanic <- titanicclean[trainIndices,]
testTitanic <- titanicclean[-trainIndices,]

model <- naiveBayes(trainTitanic[,c(6,3)],trainTitanic$Survived)
df <- data.frame(classification=predict(model,testTitanic))
cm <- confusionMatrix(df$classification,testTitanic$Survived)
cm
```


```{r}
set.seed(4)#return to seed 4
n=100
sample <- data.frame("seed"=sample(seq(1:10000),n))
dfstats <- data.frame()
for (i in 1:n) {
  #set the new seed and do 70-30 split
  set.seed(sample[i,])
  loopIndices <- sample(seq(1:length(titanicclean$Age)), round(.7*length(titanicclean$Age)))
  looptrain <- titanicclean[loopIndices,]
  looptest <- titanicclean[-loopIndices,]
  #model
  loopmodel <- naiveBayes(looptrain[,c(6,3)],looptrain$Survived)
  loopdf <- data.frame(classification=predict(loopmodel,looptest))
  loopcm <- confusionMatrix(loopdf$classification,looptest$Survived)
  loopstats <- data.frame("Accuracy"=loopcm$overall[1],
                 "Sensitivity"=loopcm$byClass[1],
                 "Specificity"=loopcm$byClass[2],
                 "Seed"=sample$seed[i],
                 row.names = i)
  dfstats <- rbind(dfstats,loopstats)
  
}
dflong <- dfstats %>%select(1:3) %>%  pivot_longer(cols = 1:3,names_to = "stats",values_to = "value")
dflong %>% ggplot(aes(x=stats,y=value, fill=stats))+geom_boxplot()+theme_hc()+scale_fill_pander()+stat_summary(fun = "mean", shape = 5, color = "white",size = .4)+ggtitle("Distribution of Accuracy, Sensitivity and Specificity")

dflong %>% group_by(stats) %>% summarise("mean"=mean(value), "median"=median(value))

```


```{r}
set.seed(4)
#add sex to the model
titanicclean <- titan %>% filter(!is.na(Age)& !is.na(Pclass))
trainIndices <- sample(seq(1:length(titanicclean$Age)), round(.7*length(titanicclean$Age)))
trainTitanic <- titanicclean[trainIndices,]
testTitanic <- titanicclean[-trainIndices,]


modelwsex <- naiveBayes(trainTitanic[,c(6,3,5)],trainTitanic$Survived)
dfwsex <- data.frame("classification"=predict(modelwsex,trainTitanic))
confusionMatrix(dfwsex$classification,trainTitanic$Survived)

```

```{r}
set.seed(4)#return to seed 4
n=100
sample <- data.frame("seed"=sample(seq(1:10000),n))
dfstats <- data.frame()
for (i in 1:n) {
  #set the new seed and do 70-30 split
  set.seed(sample[i,])
  loopIndices <- sample(seq(1:length(titanicclean$Age)), round(.7*length(titanicclean$Age)))
  looptrain <- titanicclean[loopIndices,]
  looptest <- titanicclean[-loopIndices,]
  #model
  loopmodel <- naiveBayes(looptrain[,c(6,3,5)],looptrain$Survived)
  loopdf <- data.frame(classification=predict(loopmodel,looptest))
  loopcm <- confusionMatrix(loopdf$classification,looptest$Survived)
  loopstats <- data.frame("Accuracy"=loopcm$overall[1],
                 "Sensitivity"=loopcm$byClass[1],
                 "Specificity"=loopcm$byClass[2],
                 "Seed"=sample$seed[i],
                 row.names = i)
  dfstats <- rbind(dfstats,loopstats)
  
}
dflong <- dfstats %>%select(1:3) %>%  pivot_longer(cols = 1:3,names_to = "stats",values_to = "value")
dflong %>% ggplot(aes(x=stats,y=value, fill=stats))+geom_boxplot()+theme_hc()+scale_fill_pander()+stat_summary(fun = "mean", shape = 5, color = "white",size = .4)+ggtitle("Distribution of Accuracy, Sensitivity and Specificity")

dflong %>% group_by(stats) %>% summarise("mean"=mean(value), "median"=median(value))

```


```{r}
set.seed(4)#return to seed 4
#70-30 split for Iris data set
irisall <- iris
n=100
dfstatsiris <- data.frame()
irissample <- data.frame("seed"=sample(seq(1:10000),n))

for (i in 1:n) {
  #set the new seed and do 70-30 split
  set.seed(irissample$seed[i])
  irisindx <- sample(seq(1:nrow(irisall)), round(.7*nrow(irisall)))
  iristrain <- irisall[irisindx,]
  iristest <- irisall[-irisindx,]
  #model
  irismodel <- naiveBayes(iristrain[,c(1,2)],iristrain$Species)
  irisdf <- data.frame(classification=predict(irismodel,iristest))
  iriscm <- confusionMatrix(irisdf$classification,iristest$Species)
  irisstats <- data.frame("Accuracy"=iriscm$overall[1],
                         "Sensitivity Setosa"=iriscm$byClass[1],
                         "Sensitivity Versicolor"=iriscm$byClass[2],
                         "Sensitivity Virginica"=iriscm$byClass[3],
                         "Specificity Setosa"=iriscm$byClass[4],
                         "Specificity Versicolor"=iriscm$byClass[5],
                         "Specificity Virginica"=iriscm$byClass[6],
                         "Seed"=irissample$seed[i],
                         row.names = i)
  dfstatsiris <- rbind(dfstatsiris,irisstats)
  
}
irislong <- dfstatsiris %>% pivot_longer(cols = -c(8),names_to = "stats",values_to = "value") %>% select(2:3)
irislong %>% group_by(stats) %>% summarise("mean"=mean(value),"median"=median(value))

irislong %>% ggplot(aes(x=value,y=stats, fill = stats))+geom_boxplot()+theme_hc()+scale_fill_pander()+stat_summary(fun = "mean", shape = 5, color = "white", size = .4)
?geom_boxplot
```


```{r}
#bonus
api_key <- "7tl75iH7w2vOJJUBosFdtNyVhAzBKD2E"
term <- "Trump"
begin_date <- "20220113"
end_date <- "20220212"

baseurl <- paste0("https://api.nytimes.com/svc/search/v2/articlesearch.json?q=",term,"&begin_date=",begin_date,"&end_date=",end_date,"&facet_filter=true&api-key=",api_key)
```

```{r}
#call
baseurl

initialquery <- fromJSON(baseurl)
maxPages <- round((initialquery$response$meta$hits[1]/10)-1)
maxPages

pages <- list()

for (i in 0:maxPages) {
  nytsearch <- fromJSON(paste0(baseurl,"&page=",i), flatten = TRUE) %>% data.frame()
  message("Retrieving page ",i)
  pages[[i+1]] <- nytsearch
  Sys.sleep(7)
  
}

```
```{r}
allnytsearch <- rbind_pages(pages)

#visualize
allnytsearch %>% 
  group_by(response.docs.type_of_material) %>% 
  summarise(count=n()) %>% 
  mutate(percent = (count /sum(count))*100) %>% 
  ggplot()+
  geom_col(aes(y=percent,x=response.docs.type_of_material,fill=response.docs.type_of_material))+coord_flip()
```


```{r}
#create news/other column
allnytsearch$other <- ifelse(allnytsearch$response.docs.type_of_material == "News","News","Other")

allnytsearch %>% 
  group_by(other) %>% 
  summarise(count=n()) %>% 
  mutate(percent = (count /sum(count))*100) %>% 
  ggplot()+
  geom_col(aes(y=percent,x=other,fill=other))+coord_flip()
?geom_bar
```


```{r}
set.seed(2) #set seed as class
#do a 70-30 split
n <- nrow(allnytsearch)
allnytindx <- sample(seq(1:n),round(n*.7))

nyt_train <- allnytsearch[allnytindx,]
nyt_test <- allnytsearch[-allnytindx,]
dim(nyt_test)
dim(nyt_train)
```


```{r}
#function that returns P(News|keyword)
#P(News\KW)=P(KW\News)*P(News)/P(Kw)

Pnews_word <- function(key_word, nyt_train, alphaLaplace=1, betaLaplace = 1)
{
  nyt_train$response.docs.snippet=unlist(str_replace_all(nyt_train$response.docs.snippet,"[^[:alnum:] ]",""))#leaves in only alpha numeric characters from headline
  #print(key_word)
  NewsGroup <- nyt_train[nyt_train$other=="News",]
  OtherGroup <- nyt_train[nyt_train$other=="Other",]
  
  pNews=dim(NewsGroup)[1]/(dim(NewsGroup)[1]+dim(OtherGroup)[1])
  pOther=1-pNews
  
  #meat and potatoes
  pKWGivenNews <- (length(str_which(NewsGroup$response.docs.snippet,regex(str_c("\\b",key_word,"\\b",sep=""),ignore_case = TRUE )))+alphaLaplace)/(dim(NewsGroup)[1]+betaLaplace)
  pKWGivenOther <- (length(str_which(OtherGroup$response.docs.snippet,regex(str_c("\\b",key_word,"\\b",sep=""),ignore_case = TRUE )))+alphaLaplace)/(dim(OtherGroup)[1]+betaLaplace)
  
  pKW <- length(str_which(nyt_train$response.docs.headline.main,regex(str_c("\\b",key_word,"\\b",sep=""),ignore_case = TRUE )))/(dim(nyt_train)[1])
  
  pNewsGivenKW <- pKWGivenNews*pNews/pKW
  pOtherGivenKW <- pKWGivenOther*pOther/pKW
  
  return(pNewsGivenKW)
}


```

```{r}
set.seed(2)
Pnews_word("the",nyt_train)

thescoreholdernews <- c()
thescoreholderother <- c()
articlescorenews <- 0
articlescoreother <- 0

for (i in 1:nrow(nyt_test)) {
  articlescorenews=1;#because we will multiply so we have to start with 1 so that it's 1*
  articlescoreother=1;
  #this will take out all non alpha numeric characters
  thetext <- unlist(str_split(str_replace_all(nyt_test[i,]$response.docs.headline.main,"[^[:alnum:] ]",""),boundary("word")))
  
  #stopwords
  wordstotakeout <- stopwords()
  wordstotakeout <- str_c(wordstotakeout,collapse = "\\b|\\b")
  wordstotakeout <- str_c("\\b",wordstotakeout,"\\b")
  
  importantwords <- thetext[!str_detect(thetext,regex(wordstotakeout,ignore_case = TRUE))]
  
  for (j in length(importantwords))
    {
    articlescorenews <- articlescorenews*Pnews_word(importantwords[j],nyt_train)
    articlescoreother <- articlescoreother*(1- Pnews_word(importantwords[j],nyt_train))
    
  }
  thescoreholdernews[i]=articlescorenews
  thescoreholderother[i]=articlescoreother
}

nyt_test$classified <- ifelse(thescoreholdernews>thescoreholderother,"News","Other")

table(nyt_test$classified,nyt_test$other)#actual in columns
confusionMatrix(as.factor(nyt_test$classified),as.factor(nyt_test$other))


test1reference <- data.frame(type=nyt_test[,34],from="reference")
test1classified <- data.frame(type=nyt_test[,35],from="classified")
test1 <- rbind(test1reference,test1classified)
test1 %>% ggplot(aes(x=from,fill=type))+geom_bar()+theme_hc()+scale_fill_pander()+ggtitle("NB Using Headline")
```


```{r}
#function that returns P(News|keyword)
#P(News\KW)=P(KW\News)*P(News)/P(Kw)

Pnews_word <- function(key_word, nyt_train, alphaLaplace=1, betaLaplace = 1)
{
  nyt_train$response.docs.snippet=unlist(str_replace_all(nyt_train$response.docs.snippet,"[^[:alnum:] ]",""))#leaves in only alpha numeric characters from headline
  #print(key_word)
  NewsGroup <- nyt_train[nyt_train$other=="News",]
  OtherGroup <- nyt_train[nyt_train$other=="Other",]
  
  pNews=dim(NewsGroup)[1]/(dim(NewsGroup)[1]+dim(OtherGroup)[1])
  pOther=1-pNews
  
  #meat and potatoes
  pKWGivenNews <- (length(str_which(NewsGroup$response.docs.snippet,regex(str_c("\\b",key_word,"\\b",sep=""),ignore_case = TRUE )))+alphaLaplace)/(dim(NewsGroup)[1]+betaLaplace)
  pKWGivenOther <- (length(str_which(OtherGroup$response.docs.snippet,regex(str_c("\\b",key_word,"\\b",sep=""),ignore_case = TRUE )))+alphaLaplace)/(dim(OtherGroup)[1]+betaLaplace)
  
  pKW <- length(str_which(nyt_train$response.docs.snippet,regex(str_c("\\b",key_word,"\\b",sep=""),ignore_case = TRUE )))/(dim(nyt_train)[1])
  
  pNewsGivenKW <- pKWGivenNews*pNews/pKW
  pOtherGivenKW <- pKWGivenOther*pOther/pKW
  
  return(pNewsGivenKW)
}


```

```{r}
set.seed(2)
nyt_test2 <- allnytsearch[-allnytindx,]
thescoreholdernews <- c()
thescoreholderother <- c()
articlescorenews <- 0
articlescoreother <- 0

for (i in 1:nrow(nyt_test2)) {
  articlescorenews=1;#because we will multiply so we have to start with 1 so that it's 1*
  articlescoreother=1;
  #this will take out all non alpha numeric characters
  thetext <- unlist(str_split(str_replace_all(nyt_test2[i,]$response.docs.snippet,"[^[:alnum:] ]",""),boundary("word")))
  
  #stopwords
  wordstotakeout <- stopwords()
  wordstotakeout <- str_c(wordstotakeout,collapse = "\\b|\\b")
  wordstotakeout <- str_c("\\b",wordstotakeout,"\\b")
  
  importantwords <- thetext[!str_detect(thetext,regex(wordstotakeout,ignore_case = TRUE))]
  
  for (j in length(importantwords))
    {
    articlescorenews <- articlescorenews*Pnews_word(importantwords[j],nyt_train)
    articlescoreother <- articlescoreother*(1- Pnews_word(importantwords[j],nyt_train))
    
  }
  thescoreholdernews[i]=articlescorenews
  thescoreholderother[i]=articlescoreother
}

nyt_test2$classified <- ifelse(thescoreholdernews>thescoreholderother,"News","Other")

table(nyt_test2$classified,nyt_test2$other)#actual in columns
confusionMatrix(as.factor(nyt_test2$classified),as.factor(nyt_test2$other))

test2reference <- data.frame(type=nyt_test2[,34],from="reference")
test2classified <- data.frame(type=nyt_test2[,35],from="classified")
test2 <- rbind(test2reference,test2classified)
test2 %>% ggplot(aes(x=from,fill=type))+geom_bar()+theme_hc()+scale_fill_pander()+ggtitle("NB Using Snippet")
```

